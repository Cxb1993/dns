TODO:
   movie:  mpeg1 800x600   too big for WMA on 1gz laptop
                 600x450   try this?
      iso12_1024 data:  look at intermittency? 


to get files of HPSS with stripe set:
   xpsi get -pfsComp 32 dns/decay2048/\*4026.u

Angle averging:  153 calls to transpose_z()
     1 stage RK:   9 transpose_z().  = 36 transposes per timestep
     angle averaging:  4.25 timesteps.
     True cost: 150 timesteps.
     time this again with **p replaced by multiplication?



0 BUG:  25x1x1 decomp calling output1 on 250x250x250 grid
      but 1x1x25 works fine.  
      (needs 3GB to run)

2. ns_ghost: 
        benchmark parallel decompostions
        1000^3  4th and spectral
        2000^3 on 512?
       
1. save scalars every 10 timesteps instead of at diag_dt time?
2. construct convergence test for KH problem
       use E&Liu KH problem?  what value of mu?
       mu=0:  at t=1, E is down .25e-6.  dk/dt = -1.25e-6
       mu=1.5e-6 at T=1  E is down 1.2e-4 and  dk/dt = -1.26e-4
       1e-5:  noisy
       1e-4:  a touch noisy
       2e-4: looks good, a little too smoothed 
      compare with spectral, 4th, 4th+1st order grad, or 1st order div
3. if run stops because u>1000, timings are incorrect
5. make suite of runs for diffusion: 32^3, 64^3 128^3 256^3
       plot R_lamba vs mu and h
6. switch 3d test case to different dimensions

check spectrum and rotated spectrum  (scalar)  ok for short times.
check spectrum and parallel spectrum.  using testcase?

10. use a mpi defined type for the buffer->2d array copy in transpose.F90
100. post more messages at once in tranpose.F90?  
101. divergence: go to Shashkov formula?  


**********************************************************************************
memory use:
Q: 512x512x256: formula                 288Mb per cpu
                observed:               334M

1 cpu:       formula    observed
514x514x10    362         385
130x130x130   301         326   

**********************************************************************************
sizes
Nirvana:  32Gb per box.  optimal is 225M per CPU.  
          1 box: 29Gb,  max size: 600
          2 box: 58Gb.  max size: 760 
          4 box: 116Gb  max size: 950

QidSE:  16x4 cpus.  64Gb memory
Qid:   128x4        512Gb memory


Linux box sizes:          3D array size: 3*8*n**3.  5 big arrays per run.
                                                    total size about 6 arrays
 64^3     38M            6M per array
 96^3    120M            20M per array, 100M total.  
128^3    281M            48M per array

extrapolated:
256^3   2.25Gb           .375M per variable
384^3   7.8GB
480^3:  15Gb
512^3:  18Gb             3Gb per variable  (9GB per timestep.  4.5gb   130m gridpoints
640^3   29Gb
768^3   51Gb
1024^3  144Gb            24Gb per variable                             1b gridpoints
1536^3  486Gb            81Gb per variable
2048^3  1152Gb           192Gb per variable    
3072^3  3240Gb           needs at least 1620 cpus.  6x1x512?  
4096^3  9216Gb           1536Gb per variable      
                         needs 4.6K cpus at 2GB per cpu
                         NEC ESS 10Tb

with tracers:  5 big arrays + 13D:
               (6*3  + 5*NTRACERS)*8  = 144 + 40*NTRACERS
                10 Tracers:  3.8x more memory
                 1000^3 10 tracers: 550GB = 256 cpus NO.   
                  256^3 10 tracers: 8.6GB

**********************************************************************************
analytic CFL:  for RK4, norm(G)<2.4

dealiased:  k=KMAX*(2/3) = N/3 = 1/(3delx)


advection:  G = i 2pi  (u,v,w)dot(kx,ky,kz) delt  
            |G| <= 2pi/3 delt ( U/dx + V/dy + W/dz)

    (U/dx+V/dy+W/dz) delt <= 2.4 3 / 2pi = 1.15


diffusion: G = mu 4 pi^2 (kx^2 +ky^2 + kz^2)  delt
             = mu (4/9) pi^2 delt (delx^-2 + dely^-2 + delz^-2)

      mu delt (delx^-2+dely^-2+delz^-2)  < 2.4 (9/4) / pi^2  = .55

.70: unstable
.60: seems stable.  lets go with .55



**********************************************************************************
